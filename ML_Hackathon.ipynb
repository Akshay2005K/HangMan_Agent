{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk2YXqqKIWUW",
        "outputId": "23dabb30-99c2-4a8b-bd42-613452cb05df"
      },
      "source": [
        "import os, math, random, pickle, re, numpy as np, time\n",
        "from typing import List, Set, Tuple, Dict\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/ML_Hackathon/Data\"\n",
        "CORPUS_PATH = os.path.join(DATA_DIR, \"corpus.txt\")\n",
        "TEST_PATH   = os.path.join(DATA_DIR, \"test.txt\")\n",
        "HMM_PATH    = os.path.join(DATA_DIR, \"hangman_hmm.pkl\")\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "ALPHABET  = [chr(c) for c in range(ord('a'), ord('z')+1)]\n",
        "ALPH2IDX  = {ch:i for i,ch in enumerate(ALPHABET)}\n",
        "IDX2ALPH  = {i:ch for ch,i in ALPH2IDX.items()}\n",
        "\n",
        "print(f\"Corpus Path: {CORPUS_PATH}\")\n",
        "print(f\"Test Path:   {TEST_PATH}\")\n",
        "print(f\"HMM Path:    {HMM_PATH}\")\n",
        "print(\"Google Drive paths verified.\\n\")\n",
        "\n",
        "class LetterHMM:\n",
        "    def __init__(self, alpha: float = 1.0):\n",
        "        self.alpha = alpha\n",
        "        self.pi = None\n",
        "        self.A  = None\n",
        "        self.trained = False\n",
        "\n",
        "    def read_words(self, path: str) -> List[str]:\n",
        "        with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
        "            words = [re.sub(r'[^a-z]', '', w.strip().lower()) for w in f if w.strip()]\n",
        "        return [w for w in words if w]\n",
        "\n",
        "    def train(self, words: List[str]) -> None:\n",
        "        init_cnt = Counter(); bigram_cnt = defaultdict(Counter)\n",
        "        for w in words:\n",
        "            if not w: continue\n",
        "            init_cnt[w[0]] += 1\n",
        "            for c1, c2 in zip(w[:-1], w[1:]):\n",
        "                if c1 in ALPH2IDX and c2 in ALPH2IDX:\n",
        "                    bigram_cnt[c1][c2] += 1\n",
        "        V = len(ALPHABET); a = self.alpha\n",
        "        self.pi = np.array([(init_cnt[ch]+a) for ch in ALPHABET], float)\n",
        "        self.pi /= self.pi.sum()\n",
        "        self.A = np.zeros((V,V))\n",
        "        for i,p in enumerate(ALPHABET):\n",
        "            tot = sum(bigram_cnt[p][ch] for ch in ALPHABET)+a*V\n",
        "            for j,q in enumerate(ALPHABET):\n",
        "                self.A[i,j]=(bigram_cnt[p][q]+a)/tot\n",
        "        self.trained = True\n",
        "        print(\"HMM trained.\")\n",
        "\n",
        "    def _emission_vector(self,ch,excluded):\n",
        "        e=np.zeros(26)\n",
        "        if ch==\"_\":\n",
        "            avail=[a for a in ALPHABET if a not in excluded] or ALPHABET\n",
        "            for a in avail: e[ALPH2IDX[a]]=1\n",
        "        else:\n",
        "            if ch in ALPH2IDX: e[ALPH2IDX[ch]]=1\n",
        "            else: e[:]=1\n",
        "        e/=e.sum(); return e\n",
        "\n",
        "    def _build_emissions(self,pattern,guessed):\n",
        "        wrong={g for g in guessed if g not in pattern}\n",
        "        excluded={g for g in guessed if g in ALPH2IDX}\n",
        "        E=np.zeros((len(pattern),26))\n",
        "        for i,ch in enumerate(pattern.lower()):\n",
        "            E[i]=self._emission_vector(ch,wrong|excluded)\n",
        "        return E\n",
        "\n",
        "    def _forward(self,E):\n",
        "        T=E.shape[0]; a=np.zeros_like(E); c=np.zeros(T)\n",
        "        a[0]=self.pi*E[0]; s=a[0].sum() or 1; a[0]/=s; c[0]=s\n",
        "        for t in range(1,T):\n",
        "            a[t]=(a[t-1]@self.A)*E[t]; s=a[t].sum() or 1; a[t]/=s; c[t]=s\n",
        "        return a,c\n",
        "\n",
        "    def _backward(self,E,c):\n",
        "        T=E.shape[0]; b=np.zeros_like(E); b[-1]=1/26\n",
        "        for t in range(T-2,-1,-1):\n",
        "            b[t]=self.A@(E[t+1]*b[t+1]); s=b[t].sum() or 1; b[t]/=s\n",
        "        return b\n",
        "\n",
        "    def posteriors(self,pattern,guessed):\n",
        "        E=self._build_emissions(pattern,guessed)\n",
        "        a,c=self._forward(E); b=self._backward(E,c)\n",
        "        g=a*b; g/=g.sum(axis=1,keepdims=True)\n",
        "        return g\n",
        "\n",
        "    def save(self,path):\n",
        "        with open(path,\"wb\") as f:\n",
        "            pickle.dump({'alpha':self.alpha,'pi':self.pi,'A':self.A,'trained':self.trained},f)\n",
        "\n",
        "    @classmethod\n",
        "    def load(cls,path):\n",
        "        with open(path,\"rb\") as f: obj=pickle.load(f)\n",
        "        m=cls(alpha=obj['alpha']); m.pi=obj['pi']; m.A=obj['A']; m.trained=obj['trained']; return m\n",
        "\n",
        "\n",
        "# Load or train HMM\n",
        "if os.path.exists(HMM_PATH):\n",
        "    hmm = LetterHMM.load(HMM_PATH)\n",
        "    print(\"Loaded HMM from Drive.\")\n",
        "else:\n",
        "    hmm = LetterHMM()\n",
        "    words = hmm.read_words(CORPUS_PATH)\n",
        "    hmm.train(words)\n",
        "    hmm.save(HMM_PATH)\n",
        "    print(\"HMM model saved to Drive.\")\n",
        "\n",
        "train_words = hmm.read_words(CORPUS_PATH)\n",
        "test_words  = hmm.read_words(TEST_PATH)\n",
        "print(f\"Loaded {len(train_words)} training words, {len(test_words)} test words.\\n\")\n",
        "\n",
        "class HangmanEnv:\n",
        "    def __init__(self,words,max_wrong=6):\n",
        "        self.words=words; self.max_wrong=max_wrong; self.reset()\n",
        "    def reset(self,word=None):\n",
        "        self.word=random.choice(self.words) if word is None else word\n",
        "        self.pattern=[\"_\"]*len(self.word)\n",
        "        self.guessed=set(); self.wrong=0; self.repeats=0; self.done=False\n",
        "        return self._obs()\n",
        "    def _obs(self): return (\"\".join(self.pattern),self.guessed.copy(),self.wrong,self.done)\n",
        "    def step(self,letter):\n",
        "        if self.done: return self._obs(),0,True,{}\n",
        "        if letter in self.guessed:\n",
        "            self.repeats+=1; return self._obs(),-2,False,{}\n",
        "        self.guessed.add(letter)\n",
        "        reward=0\n",
        "        if letter in self.word:\n",
        "            cnt=0\n",
        "            for i,ch in enumerate(self.word):\n",
        "                if ch==letter and self.pattern[i]==\"_\":\n",
        "                    self.pattern[i]=letter; cnt+=1\n",
        "            reward=8*cnt\n",
        "        else: self.wrong+=1; reward=-6\n",
        "        if \"_\" not in self.pattern:\n",
        "            self.done=True; reward+=60\n",
        "        elif self.wrong>=self.max_wrong:\n",
        "            self.done=True; reward-=25\n",
        "        return self._obs(),reward,self.done,{}\n",
        "\n",
        "class SmartWordMatcher:\n",
        "    def __init__(self,words):\n",
        "        self.words_by_len=defaultdict(list)\n",
        "        for w in words: self.words_by_len[len(w)].append(w)\n",
        "    def get_letter_probs(self,pattern,guessed):\n",
        "        matches=self.words_by_len.get(len(pattern),[])\n",
        "        cand=[]; wrong={g for g in guessed if g not in pattern}\n",
        "        for w in matches:\n",
        "            if any(ch in w for ch in wrong): continue\n",
        "            if all(p==\"_\" or p==w[i] for i,p in enumerate(pattern)): cand.append(w)\n",
        "        freq=np.zeros(26)\n",
        "        for w in cand:\n",
        "            for ch in set(w):\n",
        "                if ch not in guessed and ch in ALPH2IDX: freq[ALPH2IDX[ch]]+=1\n",
        "        if freq.sum()==0: freq[:]=1\n",
        "        freq/=freq.sum(); return freq\n",
        "\n",
        "def hmm_vec(hmm,pattern,guessed):\n",
        "    g=hmm.posteriors(pattern,guessed)\n",
        "    v=np.zeros(26)\n",
        "    for i,ch in enumerate(pattern):\n",
        "        if ch==\"_\": v+=g[i]\n",
        "    v=v/v.sum() if v.sum()>0 else np.ones(26)/26\n",
        "    return v\n",
        "\n",
        "class HybridPolicy:\n",
        "    def __init__(self,words):\n",
        "        self.matcher=SmartWordMatcher(words)\n",
        "        self.theta=np.random.randn(26*4+4)*0.01\n",
        "    def get_feats(self,pattern,guessed,hmm):\n",
        "        g1=hmm_vec(hmm,pattern,guessed)\n",
        "        g2=self.matcher.get_letter_probs(pattern,guessed)\n",
        "        L=6-len([g for g in guessed if g not in pattern])\n",
        "        b=pattern.count(\"_\")\n",
        "        prog=1-b/len(pattern) if len(pattern)>0 else 0\n",
        "        rev=len(pattern)-b\n",
        "        return g1,g2,L,b,prog,rev\n",
        "    def compute_scores(self,g1,g2,L,b,prog,rev,mask):\n",
        "        i=0; f1=self.theta[i:i+26]; i+=26\n",
        "        f2=self.theta[i:i+26]; i+=26\n",
        "        f3=self.theta[i:i+26]; i+=26\n",
        "        f4=self.theta[i:i+26]; i+=26\n",
        "        bL,bB,bP,bR=self.theta[i:i+4]\n",
        "        mix=0.7*g1+0.3*g2\n",
        "        s=f1*g1+f2*g2+f3*mix+f4*(g1+g2)/2\n",
        "        s+=(bL*L+bB*b+bP*prog+bR*rev)\n",
        "        s*=mask; s[mask==0]=-1e9\n",
        "        return s\n",
        "    def get_probs(self,scores,temp=1):\n",
        "        scores=scores/temp; scores-=scores.max()\n",
        "        p=np.exp(scores); p/=p.sum() if p.sum()>0 else 26\n",
        "        return p\n",
        "    def sample_action(self,pattern,guessed,hmm,temp=1):\n",
        "        g1,g2,L,b,prog,rev=self.get_feats(pattern,guessed,hmm)\n",
        "        mask=np.ones(26)\n",
        "        for ch in guessed:\n",
        "            if ch in ALPH2IDX: mask[ALPH2IDX[ch]]=0\n",
        "        s=self.compute_scores(g1,g2,L,b,prog,rev,mask)\n",
        "        p=self.get_probs(s,temp)\n",
        "        a=np.random.choice(26,p=p)\n",
        "        return a,p,(g1,g2,L,b,prog,rev,mask)\n",
        "    def greedy_action(self,pattern,guessed,hmm):\n",
        "        g1,g2,L,b,prog,rev=self.get_feats(pattern,guessed,hmm)\n",
        "        mask=np.ones(26)\n",
        "        for ch in guessed:\n",
        "            if ch in ALPH2IDX: mask[ALPH2IDX[ch]]=0\n",
        "        s=self.compute_scores(g1,g2,L,b,prog,rev,mask)\n",
        "        return np.argmax(s)\n",
        "\n",
        "def compute_grad(policy,traj,adv,_):\n",
        "    g=np.zeros_like(policy.theta)\n",
        "    for a,p,st in traj:\n",
        "        g1,g2,L,b,prog,rev,mask=st\n",
        "        d=np.zeros(26); d[a]=1; d-=p\n",
        "        i=0\n",
        "        g[i:i+26]+=adv*d*g1; i+=26\n",
        "        g[i:i+26]+=adv*d*g2; i+=26\n",
        "        g[i:i+26]+=adv*d*(0.7*g1+0.3*g2); i+=26\n",
        "        g[i:i+26]+=adv*d*(g1+g2)/2; i+=26\n",
        "        s=d.sum()\n",
        "        g[i]+=adv*s*L; i+=1; g[i]+=adv*s*b; i+=1; g[i]+=adv*s*prog; i+=1; g[i]+=adv*s*rev\n",
        "    return g\n",
        "\n",
        "def entropy_of_probs(p): return -np.sum(p*np.log(np.clip(p,1e-12,1.0)))\n",
        "\n",
        "def run_episode(env,policy,hmm,temp=1):\n",
        "    traj=[]; env.reset(); total=0; ent=0\n",
        "    for _ in range(60):\n",
        "        pat,gu,w,d=env._obs()\n",
        "        if d: break\n",
        "        a,p,st=policy.sample_action(pat,gu,hmm,temp)\n",
        "        ent+=entropy_of_probs(p)\n",
        "        _,r,d,_=env.step(ALPHABET[a])\n",
        "        total+=r; traj.append((a,p,st))\n",
        "        if d: break\n",
        "    total=float(np.clip(total,-200,200))\n",
        "    return traj,total,ent,env\n",
        "\n",
        "def evaluate_policy(policy,hmm,words,games=500):\n",
        "    env=HangmanEnv(words); wins=wrong=rep=0\n",
        "    for _ in range(games):\n",
        "        env.reset()\n",
        "        while True:\n",
        "            pat,gu,w,d=env._obs()\n",
        "            if d: break\n",
        "            a=policy.greedy_action(pat,gu,hmm)\n",
        "            _,_,d,_=env.step(ALPHABET[a])\n",
        "            if d: break\n",
        "        if \"_\" not in env.pattern: wins+=1\n",
        "        wrong+=env.wrong; rep+=env.repeats\n",
        "    succ=wins/games; score=(succ*2000)-(5*wrong)-(2*rep)\n",
        "    return succ,score\n",
        "\n",
        "def train_policy_improved(words,hmm,episodes=20000,lr=5e-4,entropy_coef=0.02,grad_clip=5.0,baseline_beta=0.995):\n",
        "    policy=HybridPolicy(words); baseline=0; best=-1e9; best_theta=policy.theta.copy()\n",
        "    env=HangmanEnv(words)\n",
        "    for ep in range(1,episodes+1):\n",
        "        temp=max(0.2,1.2-(ep/episodes))\n",
        "        traj,G,ent,e=run_episode(env,policy,hmm,temp)\n",
        "        adv=G-baseline; grad=compute_grad(policy,traj,adv,0)\n",
        "        grad += entropy_coef*np.sign(grad)*ent\n",
        "        gn=np.linalg.norm(grad)\n",
        "        if gn>grad_clip: grad*=grad_clip/(gn+1e-12)\n",
        "        policy.theta+=lr*grad\n",
        "        baseline=baseline_beta*baseline+(1-baseline_beta)*G\n",
        "        if G>best: best=G; best_theta=policy.theta.copy()\n",
        "        if ep%1000==0:\n",
        "            succ,score=evaluate_policy(policy,hmm,random.sample(words,min(500,len(words))))\n",
        "            print(f\"Ep {ep:5d} | R={G:7.2f} | Base={baseline:7.2f} | Succ={succ*100:5.2f}% | Score={score:7.1f}\")\n",
        "    policy.theta=best_theta\n",
        "    return policy\n",
        "\n",
        "print(\"Training improved policy...\\n\")\n",
        "policy=train_policy_improved(train_words,hmm,episodes=10000,lr=5e-4,entropy_coef=0.02)\n",
        "\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "succ,score=evaluate_policy(policy,hmm,test_words,games=2000)\n",
        "print(f\"\\nFinal Success Rate: {succ*100:.2f}%\")\n",
        "print(f\"Final Score: {score:.1f}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
